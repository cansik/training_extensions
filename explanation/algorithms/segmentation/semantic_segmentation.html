
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Semantic Segmentation &#8212; OpenVINO Training Extensions  documentation</title>
    
  <link href="../../../_static/css/theme.css" rel="stylesheet" />
  <link href="../../../_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/basic.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/tabs.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/panels-bootstrap.5fd3999ee7762ccc51105388f4a9d115.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/_static/css/custom.css" />
    
  <link rel="preload" as="script" href="../../../_static/js/index.1c5a1a01449ed65a7b51.js">

    <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/clipboard.min.js"></script>
    <script src="../../../_static/copybutton.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="Instance Segmentation" href="instance_segmentation.html" />
    <link rel="prev" title="Segmentation" href="index.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">

  <div id="navbar-start">
    
    

<a class="navbar-brand" href="../../../index.html">
  <img src="../../../_static/otx-logo-black-mini.png" class="logo" alt="logo">
</a>


    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
      </ul>
      </div>
      
    </div>
  </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar"><form class="bd-search d-flex align-items-center" action="../../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    <ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="../index.html">
   Algorithms
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../anomaly/index.html">
     Anomaly Recognition
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
    <label for="toctree-checkbox-2">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../anomaly/anomaly_classification.html">
       Anomaly Classificaiton
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../anomaly/anomaly_detection.html">
       Anomaly Detection
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../anomaly/anomaly_segmentation.html">
       Anomaly Segmentation
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../action/index.html">
     Action Recognition
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
    <label for="toctree-checkbox-3">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../action/action_classification.html">
       Action Classificaiton
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../action/action_detection.html">
       Action Detection
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../classification/index.html">
     Classification
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
    <label for="toctree-checkbox-4">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../classification/multi_class_classification.html">
       Multi-class Classification
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../classification/multi_label_classification.html">
       Multi-label Classification
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../classification/hierarhical_classification.html">
       Hierarchical Classification
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 current active has-children">
    <a class="reference internal" href="index.html">
     Segmentation
    </a>
    <input checked="" class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
    <label for="toctree-checkbox-5">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul class="current">
     <li class="toctree-l3 current active">
      <a class="current reference internal" href="#">
       Semantic Segmentation
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="instance_segmentation.html">
       Instance Segmentation
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../object_detection/index.html">
     Object Detection
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
    <label for="toctree-checkbox-6">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../object_detection/object_detection.html">
       Object Detection
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../object_detection/rotated_object_detection.html">
       Object Detection With Rotated Bounding Boxes
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../additional_features/index.html">
   Additional Features
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../additional_features/models_optimization.html">
     Models Optimization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../additional_features/hpo.html">
     Hyperparameters Oprimization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../additional_features/auto_configuration.html">
     Auto-configuration
    </a>
   </li>
  </ul>
 </li>
</ul>

  </div>
</nav>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
            
              
              <div class="toc-item">
                
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#dataset-format">
   Dataset Format
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#models">
   Models
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#semi-supervised-learning">
   Semi-supervised Learning
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#self-supervised-learning">
   Self-supervised Learning
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#incremental-learning">
   Incremental Learning
  </a>
 </li>
</ul>

</nav>
              </div>
              
              <div class="toc-item">
                
              </div>
              
            
          </div>
          

          
          
            
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <div class="section" id="semantic-segmentation">
<h1>Semantic Segmentation<a class="headerlink" href="#semantic-segmentation" title="Permalink to this headline">¶</a></h1>
<p>Semantic segmentation is a computer vision task in which an algorithm assigns a label or class to each pixel in an image.
For example, semantic segmentation can be used to identify the boundaries of different objects in an image, such as cars, buildings, and trees.
The output of semantic segmentation is typically an image where each pixel is colored with a different color or label depending on its class.</p>
<div class="line-block">
<div class="line"><br /></div>
</div>
<a class="reference internal image-reference" href="../../../_images/semantic_seg_example.png"><img alt="image uploaded from this `source &lt;https://arxiv.org/abs/1912.03183&gt;`_" src="../../../_images/semantic_seg_example.png" style="width: 600px;" /></a>
<div class="line-block">
<div class="line"><br /></div>
</div>
<p>We solve this task by utilizing <a class="reference external" href="https://arxiv.org/pdf/1411.4038.pdf">FCN Head</a> with implementation from <a class="reference external" href="https://mmsegmentation.readthedocs.io/en/latest/_modules/mmseg/models/decode_heads/fcn_head.html">MMSegmentation</a> on the multi-level image features obtained by the feature extractor backbone (<a class="reference external" href="https://arxiv.org/abs/2104.06403">Lite-HRNet</a>).
For the supervised training we use the following algorithms components:</p>
<ul class="simple" id="semantic-segmentation-supervised-pipeline">
<li><p><code class="docutils literal notranslate"><span class="pre">Augmentations</span></code>: Besides basic augmentations like random flip, random rotate and random crop, we use mixing images technique with different <a class="reference external" href="https://mmsegmentation.readthedocs.io/en/latest/api.html#mmseg.datasets.pipelines.PhotoMetricDistortion">photometric distortions</a>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Optimizer</span></code>: We use <a class="reference external" href="https://arxiv.org/abs/1412.6980">Adam</a> optimizer with weight decay set to zero and gradient clipping with maximum quadratic norm equals to 40.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Learning</span> <span class="pre">rate</span> <span class="pre">schedule</span></code>: For scheduling training process we use <strong>ReduceLROnPlataeu</strong> with linear learning rate warmup for 100 iterations. This method monitors a target metric (in our case we use metric on the validation set) and if no improvement is seen for a ‘patience’ number of epochs, the learning rate is reduced.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Loss</span> <span class="pre">function</span></code>: We use standart <a class="reference external" href="https://en.wikipedia.org/wiki/Cross_entropy">Cross Entropy Loss</a>  to train a model.</p></li>
<li><p>Additionally, we use the <strong>early stopping</strong> to add adaptability to the training pipeline and prevent overfitting.</p></li>
</ul>
<div class="section" id="dataset-format">
<h2>Dataset Format<a class="headerlink" href="#dataset-format" title="Permalink to this headline">¶</a></h2>
<p>For the dataset handling inside OTX we use <a class="reference external" href="https://github.com/openvinotoolkit/datumaro">Dataset Management Framework (Datumaro)</a>.</p>
<p>At this end we support <a class="reference external" href="https://openvinotoolkit.github.io/datumaro/docs/formats/ade20k2020/">ADE20K</a>, <a class="reference external" href="https://openvinotoolkit.github.io/datumaro/docs/formats/cityscapes/">Cityscapes</a>, <a class="reference external" href="https://openvinotoolkit.github.io/datumaro/docs/formats/pascal_voc/">Pascal VOC</a> and <a class="reference external" href="https://openvinotoolkit.github.io/datumaro/docs/formats/common_semantic_segmentation/">Common Semantic Segmentation</a> data formats.
If you organized supported dataset format, starting training will be very simple. We just need to pass a path to the root folder and desired model template to start training:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ otx train --template &lt;model_template&gt; --train-data-root &lt;path_to_data_root&gt; --val-data-root &lt;path_to_data_root&gt;
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Please, refer to our <a class="reference internal" href="../../../tutorials/base/how_to_train/semantic_segmentation.html"><span class="doc">dedicated tutorial</span></a> for more information on how to train, validate and optimize semantic segmentation model for more details.</p>
</div>
</div>
<div class="section" id="models">
<h2>Models<a class="headerlink" href="#models" title="Permalink to this headline">¶</a></h2>
<p>We support the following ready-to-use model templates:</p>
<p>All of these models are members of the same <a class="reference external" href="https://arxiv.org/abs/2104.06403">Lite-HRNet</a> backbones family. They differ in the trade-off between accuracy and inference/training speed. <code class="docutils literal notranslate"><span class="pre">Lite-HRNet-x-mod3</span></code> is the template with heavy-size architecture for accurate predictions but it requires long training.
Whereas the <code class="docutils literal notranslate"><span class="pre">Lite-HRNet-s-mod2</span></code> is the lightweight architecture for fast inference and training. It is the best choice for the scenario of a limited amount of data. The <code class="docutils literal notranslate"><span class="pre">Lite-HRNet-18-mod2</span></code> model is the middle-sized architecture for the balance between fast inference and training time.</p>
<p>In the table below the <a class="reference external" href="https://en.wikipedia.org/wiki/S%C3%B8rensen%E2%80%93Dice_coefficient">Dice score</a> on some academic datasets using our <a class="reference internal" href="#semantic-segmentation-supervised-pipeline"><span class="std std-ref">supervised pipeline</span></a> is presented. The results were obtained on our templates without any changes. We use 512x512 image crop resolution, for other hyperparameters, please, refer to the related template. We trained each model with single Nvidia GeForce RTX3090.</p>
<table class="table">
<colgroup>
<col style="width: 35%" />
<col style="width: 21%" />
<col style="width: 18%" />
<col style="width: 26%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Model name</p></th>
<th class="head"><p>ADE20k</p></th>
<th class="head"><p>Cityscapes</p></th>
<th class="head"><p>Pascal-VOC 2012</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Lite-HRNet-s-mod2</p></td>
<td><p>N/A</p></td>
<td><p>N/A</p></td>
<td><p>N/A</p></td>
</tr>
<tr class="row-odd"><td><p>Lite-HRNet-18-mod2</p></td>
<td><p>N/A</p></td>
<td><p>N/A</p></td>
<td><p>N/A</p></td>
</tr>
<tr class="row-even"><td><p>Lite-HRNet-x-mod3</p></td>
<td><p>N/A</p></td>
<td><p>N/A</p></td>
<td><p>N/A</p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="semi-supervised-learning">
<h2>Semi-supervised Learning<a class="headerlink" href="#semi-supervised-learning" title="Permalink to this headline">¶</a></h2>
<p>To solve <a class="reference internal" href="../index.html#semi-sl-explanation"><span class="std std-ref">Semi-supervised learning</span></a> problem for the semantic segmentation we use the <a class="reference external" href="https://arxiv.org/abs/1703.01780">Mean Teacher algorithm</a>. The basic idea of this approach is to use two models during training: a “student” model, which is the main model being trained, and a “teacher” model, which acts as a guide for the student model.
The student model is updated based on the ground truth annotations (for the labeled data) and pseudo-labels (for the unlabeled data) which are the predictions of the teacher model.
The teacher model is updated based on the moving average of the student model’s parameters. So, we don’t use backward loss propagation for the teacher model’s parameters.
After training, only the student model is used for prediction.</p>
<p>We utilize the same core algorithm’s parameters as for the <a class="reference internal" href="#semantic-segmentation-supervised-pipeline"><span class="std std-ref">supervised pipeline</span></a>. The main difference is to use of different augmentation pipelines for the labeled and unlabeled data.
We use only basic augmentations (random flip, random rotate, random crop) for the labeled data and stronger for the unlabeled (color distortion).
It helps with a better generalization and prevents unnecessary overfitting on the pseudo-labels generated by the teacher model.</p>
<p>In the table below the <a class="reference external" href="https://en.wikipedia.org/wiki/S%C3%B8rensen%E2%80%93Dice_coefficient">Dice score</a> with our middle template on some datasets is presented. For comparison, we present the supervised baseline trained on the labeled data only.
The results were obtained on our templates without any changes. We use 512x512 image resolution, for other hyperparameters, please, refer to the <a class="reference external" href="https://github.com/openvinotoolkit/training_extensions/blob/develop/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18_mod2/template.yaml">related template</a>. We trained each model with single Nvidia GeForce RTX3090.
For <a class="reference external" href="https://www.cityscapes-dataset.com/">Cityscapes</a> and <a class="reference external" href="http://host.robots.ox.ac.uk/pascal/VOC/voc2012/index.html">Pascal-VOC</a> we use splits with different ratios of labeled to unlabeled data like <a class="reference external" href="https://github.com/charlesCXK/TorchSemiSeg">here</a>.
For the <a class="reference external" href="https://xuebinqin.github.io/dis/index.html">DIS5K</a> we prepared random splits for the train data with different ratios of labeled to unlabeled images. We use the validation set for testing purposes.</p>
<table class="table">
<colgroup>
<col style="width: 46%" />
<col style="width: 18%" />
<col style="width: 15%" />
<col style="width: 21%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Model name</p></th>
<th class="head"><p>DIS5K</p></th>
<th class="head"><p>Cityscapes</p></th>
<th class="head"><p>Pascal-VOC</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Supervised Lite-HRNet-18-mod2 (1/8)</p></td>
<td><p>N/A</p></td>
<td><p>N/A</p></td>
<td><p>N/A</p></td>
</tr>
<tr class="row-odd"><td><p>Semi-SL Lite-HRNet-18-mod2 (1/8)</p></td>
<td><p>N/A</p></td>
<td><p>N/A</p></td>
<td><p>N/A</p></td>
</tr>
<tr class="row-even"><td><p>Supervised Lite-HRNet-18-mod2 (1/16)</p></td>
<td><p>N/A</p></td>
<td><p>N/A</p></td>
<td><p>N/A</p></td>
</tr>
<tr class="row-odd"><td><p>Semi-SL Lite-HRNet-18-mod2 (1/16)</p></td>
<td><p>N/A</p></td>
<td><p>N/A</p></td>
<td><p>N/A</p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="self-supervised-learning">
<h2>Self-supervised Learning<a class="headerlink" href="#self-supervised-learning" title="Permalink to this headline">¶</a></h2>
<p>To be added soon</p>
</div>
<div class="section" id="incremental-learning">
<h2>Incremental Learning<a class="headerlink" href="#incremental-learning" title="Permalink to this headline">¶</a></h2>
<p>To be added soon</p>
</div>
</div>


              </div>
              
              
              <div class='prev-next-bottom'>
                
    <a class='left-prev' id="prev-link" href="index.html" title="previous page">Segmentation</a>
    <a class='right-next' id="next-link" href="instance_segmentation.html" title="next page">Instance Segmentation</a>

              </div>
              
          </main>
          

      </div>
    </div>
  
  <script src="../../../_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  <footer class="footer mt-5 mt-md-0">
  <div class="container">
    
    <div class="footer-item">
      <p class="copyright">
    &copy; Copyright 2022, OpenVINO Training Extensions Contributors.<br/>
</p>
    </div>
    
    <div class="footer-item">
      <p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 4.2.0.<br/>
</p>
    </div>
    
  </div>
</footer>
  </body>
</html>