<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>otx.api.usecases.evaluation.dice &mdash; OpenVINO Training Extensions  documentation</title>
      <link rel="stylesheet" href="../../../../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../../../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../../../../_static/graphviz.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../../../../" id="documentation_options" src="../../../../../_static/documentation_options.js"></script>
        <script src="../../../../../_static/jquery.js"></script>
        <script src="../../../../../_static/underscore.js"></script>
        <script src="../../../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../../../../../_static/doctools.js"></script>
    <script src="../../../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../../../../index.html" class="icon icon-home"> OpenVINO Training Extensions
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../api/index.html">API Reference</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../../index.html">OpenVINO Training Extensions</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../../../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="../../../../index.html">Module code</a> &raquo;</li>
          <li><a href="../../../../otx.html">otx</a> &raquo;</li>
      <li>otx.api.usecases.evaluation.dice</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for otx.api.usecases.evaluation.dice</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;This module contains the Dice performance provider.&quot;&quot;&quot;</span>

<span class="c1"># Copyright (C) 2021-2022 Intel Corporation</span>
<span class="c1"># SPDX-License-Identifier: Apache-2.0</span>
<span class="c1">#</span>


<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Tuple</span>

<span class="kn">from</span> <span class="nn">otx.api.entities.label</span> <span class="kn">import</span> <span class="n">LabelEntity</span>
<span class="kn">from</span> <span class="nn">otx.api.entities.metrics</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">BarChartInfo</span><span class="p">,</span>
    <span class="n">BarMetricsGroup</span><span class="p">,</span>
    <span class="n">ColorPalette</span><span class="p">,</span>
    <span class="n">MetricsGroup</span><span class="p">,</span>
    <span class="n">Performance</span><span class="p">,</span>
    <span class="n">ScoreMetric</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">otx.api.entities.resultset</span> <span class="kn">import</span> <span class="n">ResultSetEntity</span>
<span class="kn">from</span> <span class="nn">otx.api.usecases.evaluation.averaging</span> <span class="kn">import</span> <span class="n">MetricAverageMethod</span>
<span class="kn">from</span> <span class="nn">otx.api.usecases.evaluation.basic_operations</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">get_intersections_and_cardinalities</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">otx.api.usecases.evaluation.performance_provider_interface</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">IPerformanceProvider</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">otx.api.utils.segmentation_utils</span> <span class="kn">import</span> <span class="n">mask_from_dataset_item</span>
<span class="kn">from</span> <span class="nn">otx.api.utils.time_utils</span> <span class="kn">import</span> <span class="n">timeit</span>


<div class="viewcode-block" id="DiceAverage"><a class="viewcode-back" href="../../../../../api/otx/api/usecases/evaluation/index.html#otx.api.usecases.evaluation.dice.DiceAverage">[docs]</a><span class="k">class</span> <span class="nc">DiceAverage</span><span class="p">(</span><span class="n">IPerformanceProvider</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Computes the average Dice coefficient overall and for individual labels.</span>

<span class="sd">    See https://en.wikipedia.org/wiki/S%C3%B8rensen%E2%80%93Dice_coefficient for background information.</span>

<span class="sd">    To compute the Dice coefficient the shapes in the dataset items of the prediction and ground truth</span>
<span class="sd">    dataset are first converted to masks.</span>

<span class="sd">    Dice is computed by computing the intersection and union computed over the whole dataset, instead of</span>
<span class="sd">    computing intersection and union for individual images and then averaging.</span>

<span class="sd">    Args:</span>
<span class="sd">        resultset (ResultSetEntity): ResultSet that score will be computed for</span>
<span class="sd">        average (MetricAverageMethod): One of</span>
<span class="sd">            - MICRO: every pixel has the same weight, regardless of label</span>
<span class="sd">            - MACRO: compute score per label, return the average of the per-label scores</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">resultset</span><span class="p">:</span> <span class="n">ResultSetEntity</span><span class="p">,</span>
        <span class="n">average</span><span class="p">:</span> <span class="n">MetricAverageMethod</span> <span class="o">=</span> <span class="n">MetricAverageMethod</span><span class="o">.</span><span class="n">MACRO</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">average</span> <span class="o">=</span> <span class="n">average</span>
        <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_overall_dice</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_dice_per_label</span><span class="p">,</span>
        <span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__compute_dice_averaged_over_pixels</span><span class="p">(</span><span class="n">resultset</span><span class="p">,</span> <span class="n">average</span><span class="p">)</span>

    <span class="nd">@property</span>
<div class="viewcode-block" id="DiceAverage.overall_dice"><a class="viewcode-back" href="../../../../../api/otx/api/usecases/evaluation/dice/index.html#otx.api.usecases.evaluation.dice.DiceAverage.overall_dice">[docs]</a>    <span class="k">def</span> <span class="nf">overall_dice</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ScoreMetric</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Returns the dice average as ScoreMetric.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_overall_dice</span></div>

    <span class="nd">@property</span>
<div class="viewcode-block" id="DiceAverage.dice_per_label"><a class="viewcode-back" href="../../../../../api/otx/api/usecases/evaluation/dice/index.html#otx.api.usecases.evaluation.dice.DiceAverage.dice_per_label">[docs]</a>    <span class="k">def</span> <span class="nf">dice_per_label</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="n">LabelEntity</span><span class="p">,</span> <span class="n">ScoreMetric</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Returns a dictionary mapping the label to its corresponding dice score (as ScoreMetric).&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dice_per_label</span></div>

<div class="viewcode-block" id="DiceAverage.get_performance"><a class="viewcode-back" href="../../../../../api/otx/api/usecases/evaluation/dice/index.html#otx.api.usecases.evaluation.dice.DiceAverage.get_performance">[docs]</a>    <span class="k">def</span> <span class="nf">get_performance</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Performance</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Returns the performance of the resultset.&quot;&quot;&quot;</span>
        <span class="n">score</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">overall_dice</span>
        <span class="n">dashboard_metrics</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">MetricsGroup</span><span class="p">]]</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dice_per_label</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">dashboard_metrics</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">dashboard_metrics</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">BarMetricsGroup</span><span class="p">(</span>
                    <span class="n">metrics</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dice_per_label</span><span class="o">.</span><span class="n">values</span><span class="p">()),</span>
                    <span class="n">visualization_info</span><span class="o">=</span><span class="n">BarChartInfo</span><span class="p">(</span>
                        <span class="n">name</span><span class="o">=</span><span class="s2">&quot;Dice Average Per Label&quot;</span><span class="p">,</span>
                        <span class="n">palette</span><span class="o">=</span><span class="n">ColorPalette</span><span class="o">.</span><span class="n">LABEL</span><span class="p">,</span>
                    <span class="p">),</span>
                <span class="p">)</span>
            <span class="p">]</span>
        <span class="k">return</span> <span class="n">Performance</span><span class="p">(</span><span class="n">score</span><span class="o">=</span><span class="n">score</span><span class="p">,</span> <span class="n">dashboard_metrics</span><span class="o">=</span><span class="n">dashboard_metrics</span><span class="p">)</span></div>

    <span class="nd">@classmethod</span>
    <span class="nd">@timeit</span>
<div class="viewcode-block" id="DiceAverage.__compute_dice_averaged_over_pixels"><a class="viewcode-back" href="../../../../../api/otx/api/usecases/evaluation/dice/index.html#otx.api.usecases.evaluation.dice.DiceAverage.__compute_dice_averaged_over_pixels">[docs]</a>    <span class="k">def</span> <span class="nf">__compute_dice_averaged_over_pixels</span><span class="p">(</span>
        <span class="bp">cls</span><span class="p">,</span> <span class="n">resultset</span><span class="p">:</span> <span class="n">ResultSetEntity</span><span class="p">,</span> <span class="n">average</span><span class="p">:</span> <span class="n">MetricAverageMethod</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">ScoreMetric</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="n">LabelEntity</span><span class="p">,</span> <span class="n">ScoreMetric</span><span class="p">]]:</span>
        <span class="sd">&quot;&quot;&quot;Computes the diced averaged over pixels.</span>

<span class="sd">        Args:</span>
<span class="sd">            resultset (ResultSetEntity): Result set to use</span>
<span class="sd">            average (MetricAverageMethod): Averaging method to use</span>

<span class="sd">        Returns:</span>
<span class="sd">            Tuple[ScoreMetric, Dict[LabelEntity, ScoreMetric]]: Tuple of the overall dice and the dice averaged over</span>
<span class="sd">                pixels for each label.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">resultset</span><span class="o">.</span><span class="n">prediction_dataset</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Cannot compute the DICE score of an empty result set.&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">resultset</span><span class="o">.</span><span class="n">prediction_dataset</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">resultset</span><span class="o">.</span><span class="n">ground_truth_dataset</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Prediction and ground truth dataset should have the same length. &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;Ground truth dataset has </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">resultset</span><span class="o">.</span><span class="n">ground_truth_dataset</span><span class="p">)</span><span class="si">}</span><span class="s2"> items, &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;prediction dataset has </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">resultset</span><span class="o">.</span><span class="n">prediction_dataset</span><span class="p">)</span><span class="si">}</span><span class="s2"> items&quot;</span>
            <span class="p">)</span>
        <span class="n">resultset_labels</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">resultset</span><span class="o">.</span><span class="n">prediction_dataset</span><span class="o">.</span><span class="n">get_labels</span><span class="p">()</span> <span class="o">+</span> <span class="n">resultset</span><span class="o">.</span><span class="n">ground_truth_dataset</span><span class="o">.</span><span class="n">get_labels</span><span class="p">())</span>
        <span class="n">model_labels</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">resultset</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">configuration</span><span class="o">.</span><span class="n">get_label_schema</span><span class="p">()</span><span class="o">.</span><span class="n">get_labels</span><span class="p">(</span><span class="n">include_empty</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">resultset_labels</span><span class="o">.</span><span class="n">intersection</span><span class="p">(</span><span class="n">model_labels</span><span class="p">))</span>
        <span class="n">hard_predictions</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">hard_references</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">prediction_item</span><span class="p">,</span> <span class="n">reference_item</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span>
            <span class="nb">list</span><span class="p">(</span><span class="n">resultset</span><span class="o">.</span><span class="n">prediction_dataset</span><span class="p">),</span> <span class="nb">list</span><span class="p">(</span><span class="n">resultset</span><span class="o">.</span><span class="n">ground_truth_dataset</span><span class="p">)</span>
        <span class="p">):</span>
            <span class="n">hard_predictions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">mask_from_dataset_item</span><span class="p">(</span><span class="n">prediction_item</span><span class="p">,</span> <span class="n">labels</span><span class="p">))</span>
            <span class="n">hard_references</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">mask_from_dataset_item</span><span class="p">(</span><span class="n">reference_item</span><span class="p">,</span> <span class="n">labels</span><span class="p">))</span>

        <span class="n">all_intersection</span><span class="p">,</span> <span class="n">all_cardinality</span> <span class="o">=</span> <span class="n">get_intersections_and_cardinalities</span><span class="p">(</span>
            <span class="n">hard_references</span><span class="p">,</span> <span class="n">hard_predictions</span><span class="p">,</span> <span class="n">labels</span>
        <span class="p">)</span>

        <span class="k">return</span> <span class="bp">cls</span><span class="o">.</span><span class="n">compute_dice_using_intersection_and_cardinality</span><span class="p">(</span><span class="n">all_intersection</span><span class="p">,</span> <span class="n">all_cardinality</span><span class="p">,</span> <span class="n">average</span><span class="p">)</span></div>

    <span class="nd">@classmethod</span>
<div class="viewcode-block" id="DiceAverage.compute_dice_using_intersection_and_cardinality"><a class="viewcode-back" href="../../../../../api/otx/api/usecases/evaluation/dice/index.html#otx.api.usecases.evaluation.dice.DiceAverage.compute_dice_using_intersection_and_cardinality">[docs]</a>    <span class="k">def</span> <span class="nf">compute_dice_using_intersection_and_cardinality</span><span class="p">(</span>
        <span class="bp">cls</span><span class="p">,</span>
        <span class="n">all_intersection</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="n">Optional</span><span class="p">[</span><span class="n">LabelEntity</span><span class="p">],</span> <span class="nb">int</span><span class="p">],</span>
        <span class="n">all_cardinality</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="n">Optional</span><span class="p">[</span><span class="n">LabelEntity</span><span class="p">],</span> <span class="nb">int</span><span class="p">],</span>
        <span class="n">average</span><span class="p">:</span> <span class="n">MetricAverageMethod</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">ScoreMetric</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="n">LabelEntity</span><span class="p">,</span> <span class="n">ScoreMetric</span><span class="p">]]:</span>
        <span class="sd">&quot;&quot;&quot;Computes dice score using intersection and cardinality dictionaries.</span>

<span class="sd">        Both dictionaries must contain the same set of keys.</span>
<span class="sd">        Dice score is computed by: 2 * intersection / cardinality</span>

<span class="sd">        Args:</span>
<span class="sd">            average: Averaging method to use</span>
<span class="sd">            all_intersection: collection of intersections per label</span>
<span class="sd">            all_cardinality: collection of cardinality per label</span>

<span class="sd">        Returns:</span>
<span class="sd">            A tuple containing the overall DICE score, and per label</span>
<span class="sd">            DICE score</span>

<span class="sd">        Raises:</span>
<span class="sd">            KeyError: if the keys in intersection and cardinality do not</span>
<span class="sd">                match</span>
<span class="sd">            KeyError: if the key `None` is not present in either</span>
<span class="sd">                all_intersection or all_cardinality</span>
<span class="sd">            ValueError: if the intersection for a certain key is larger</span>
<span class="sd">                than its corresponding cardinality</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">dice_per_label</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="n">LabelEntity</span><span class="p">,</span> <span class="n">ScoreMetric</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="k">for</span> <span class="n">label</span><span class="p">,</span> <span class="n">intersection</span> <span class="ow">in</span> <span class="n">all_intersection</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">cardinality</span> <span class="o">=</span> <span class="n">all_cardinality</span><span class="p">[</span><span class="n">label</span><span class="p">]</span>
            <span class="n">dice_score</span> <span class="o">=</span> <span class="bp">cls</span><span class="o">.</span><span class="n">__compute_single_dice_score_using_intersection_and_cardinality</span><span class="p">(</span><span class="n">intersection</span><span class="p">,</span> <span class="n">cardinality</span><span class="p">)</span>

            <span class="c1"># If label is None, then the dice score corresponds to the overall dice score</span>
            <span class="c1"># rather than a per-label dice score.</span>
            <span class="c1"># This score is calculated last because it can depend on the values in dice_per_label</span>
            <span class="k">if</span> <span class="n">label</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">dice_per_label</span><span class="p">[</span><span class="n">label</span><span class="p">]</span> <span class="o">=</span> <span class="n">ScoreMetric</span><span class="p">(</span><span class="n">value</span><span class="o">=</span><span class="n">dice_score</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">label</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>

        <span class="c1"># Set overall_dice to 0 in case the score cannot be computed</span>
        <span class="n">overall_dice</span> <span class="o">=</span> <span class="n">ScoreMetric</span><span class="p">(</span><span class="n">value</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;Dice Average&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">dice_per_label</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>  <span class="c1"># dataset consists of background pixels only</span>
            <span class="k">pass</span>  <span class="c1"># Use the default value of 0</span>
        <span class="k">elif</span> <span class="n">average</span> <span class="o">==</span> <span class="n">MetricAverageMethod</span><span class="o">.</span><span class="n">MICRO</span><span class="p">:</span>
            <span class="n">overall_cardinality</span> <span class="o">=</span> <span class="n">all_cardinality</span><span class="p">[</span><span class="kc">None</span><span class="p">]</span>
            <span class="n">overall_intersection</span> <span class="o">=</span> <span class="n">all_intersection</span><span class="p">[</span><span class="kc">None</span><span class="p">]</span>
            <span class="n">dice_score</span> <span class="o">=</span> <span class="bp">cls</span><span class="o">.</span><span class="n">__compute_single_dice_score_using_intersection_and_cardinality</span><span class="p">(</span>
                <span class="n">overall_intersection</span><span class="p">,</span> <span class="n">overall_cardinality</span>
            <span class="p">)</span>
            <span class="n">overall_dice</span> <span class="o">=</span> <span class="n">ScoreMetric</span><span class="p">(</span><span class="n">value</span><span class="o">=</span><span class="n">dice_score</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;Dice Average&quot;</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">average</span> <span class="o">==</span> <span class="n">MetricAverageMethod</span><span class="o">.</span><span class="n">MACRO</span><span class="p">:</span>
            <span class="n">scores</span> <span class="o">=</span> <span class="p">[</span><span class="n">item</span><span class="o">.</span><span class="n">value</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">dice_per_label</span><span class="o">.</span><span class="n">values</span><span class="p">()]</span>
            <span class="n">macro_average_score</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span>
            <span class="n">overall_dice</span> <span class="o">=</span> <span class="n">ScoreMetric</span><span class="p">(</span><span class="n">value</span><span class="o">=</span><span class="n">macro_average_score</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;Dice Average&quot;</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">overall_dice</span><span class="p">,</span> <span class="n">dice_per_label</span></div>

    <span class="nd">@staticmethod</span>
<div class="viewcode-block" id="DiceAverage.__compute_single_dice_score_using_intersection_and_cardinality"><a class="viewcode-back" href="../../../../../api/otx/api/usecases/evaluation/dice/index.html#otx.api.usecases.evaluation.dice.DiceAverage.__compute_single_dice_score_using_intersection_and_cardinality">[docs]</a>    <span class="k">def</span> <span class="nf">__compute_single_dice_score_using_intersection_and_cardinality</span><span class="p">(</span><span class="n">intersection</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">cardinality</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Computes a single dice score using intersection and cardinality.</span>

<span class="sd">        Dice score is computed by: 2 * intersection / cardinality</span>

<span class="sd">        Raises:</span>
<span class="sd">            ValueError: If intersection is larger than cardinality</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">intersection</span> <span class="o">&gt;</span> <span class="n">cardinality</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;intersection cannot be larger than cardinality&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">cardinality</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">intersection</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">dice_score</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">dice_score</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">intersection</span> <span class="o">/</span> <span class="n">cardinality</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">dice_score</span></div></div>
</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, OpenVINO Training Extensions Contributors.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>