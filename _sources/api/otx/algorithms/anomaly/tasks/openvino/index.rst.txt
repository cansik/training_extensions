:py:mod:`otx.algorithms.anomaly.tasks.openvino`
===============================================

.. py:module:: otx.algorithms.anomaly.tasks.openvino

.. autoapi-nested-parse::

   OpenVINO Anomaly Task.



Module Contents
---------------

Classes
~~~~~~~

.. autoapisummary::

   otx.algorithms.anomaly.tasks.openvino.OTXOpenVINOAnomalyDataloader
   otx.algorithms.anomaly.tasks.openvino.OpenVINOTask




Attributes
~~~~~~~~~~

.. autoapisummary::

   otx.algorithms.anomaly.tasks.openvino.logger


.. py:data:: logger
   

   

.. py:class:: OTXOpenVINOAnomalyDataloader(config: addict.Dict, dataset: otx.api.entities.datasets.DatasetEntity, inferencer: anomalib.deploy.OpenVINOInferencer)

   Bases: :py:obj:`compression.api.DataLoader`

   Dataloader for loading OTX dataset into OTX OpenVINO Inferencer.

   :param dataset: OTX dataset entity
   :type dataset: DatasetEntity
   :param inferencer: OpenVINO Inferencer
   :type inferencer: OpenVINOInferencer

   .. py:method:: __getitem__(index: int)

      Get dataset item.

      :param index: Index of the dataset sample.
      :type index: int

      :returns: Dataset item.


   .. py:method:: __len__() -> int

      Get size of the dataset.

      :returns: Size of the dataset.
      :rtype: int



.. py:class:: OpenVINOTask(task_environment: otx.api.entities.task_environment.TaskEnvironment)

   Bases: :py:obj:`otx.api.usecases.tasks.interfaces.inference_interface.IInferenceTask`, :py:obj:`otx.api.usecases.tasks.interfaces.evaluate_interface.IEvaluationTask`, :py:obj:`otx.api.usecases.tasks.interfaces.optimization_interface.IOptimizationTask`, :py:obj:`otx.api.usecases.tasks.interfaces.deployment_interface.IDeploymentTask`

   OpenVINO inference task.

   :param task_environment: task environment of the trained anomaly model
   :type task_environment: TaskEnvironment

   .. py:method:: get_config() -> addict.Dict

      Get Anomalib Config from task environment.

      :returns: Anomalib config
      :rtype: ADDict


   .. py:method:: infer(dataset: otx.api.entities.datasets.DatasetEntity, inference_parameters: otx.api.entities.inference_parameters.InferenceParameters) -> otx.api.entities.datasets.DatasetEntity

      Perform Inference.

      :param dataset: Inference dataset
      :type dataset: DatasetEntity
      :param inference_parameters: Inference parameters.
      :type inference_parameters: InferenceParameters

      :returns: Output dataset storing inference predictions.
      :rtype: DatasetEntity


   .. py:method:: get_meta_data() -> Dict

      Get Meta Data.


   .. py:method:: evaluate(output_resultset: otx.api.entities.resultset.ResultSetEntity, evaluation_metric: Optional[str] = None)

      Evaluate the performance of the model.

      :param output_resultset: Result set storing ground truth and predicted dataset.
      :type output_resultset: ResultSetEntity
      :param evaluation_metric: Evaluation metric. Defaults to None.
      :type evaluation_metric: Optional[str], optional


   .. py:method:: _get_optimization_algorithms_configs() -> List[addict.Dict]

      Returns list of optimization algorithms configurations.


   .. py:method:: optimize(optimization_type: otx.api.usecases.tasks.interfaces.optimization_interface.OptimizationType, dataset: otx.api.entities.datasets.DatasetEntity, output_model: otx.api.entities.model.ModelEntity, optimization_parameters: Optional[otx.api.entities.optimization_parameters.OptimizationParameters])

      Optimize the model.

      :param optimization_type: Type of optimization [POT or NNCF]
      :type optimization_type: OptimizationType
      :param dataset: Input Dataset.
      :type dataset: DatasetEntity
      :param output_model: Output model.
      :type output_model: ModelEntity
      :param optimization_parameters: Optimization parameters.
      :type optimization_parameters: Optional[OptimizationParameters]

      :raises ValueError: When the optimization type is not POT, which is the only support type at the moment.


   .. py:method:: load_inferencer() -> anomalib.deploy.OpenVINOInferencer

      Create the OpenVINO inferencer object.

      :returns: OpenVINOInferencer object


   .. py:method:: __save_weights(path: str, data: bytes) -> None
      :staticmethod:

      Write data to file.

      :param path: Path of output file
      :type path: str
      :param data: Data to write
      :type data: bytes


   .. py:method:: __load_weights(path: str, output_model: otx.api.entities.model.ModelEntity, key: str) -> None
      :staticmethod:

      Load weights into output model.

      :param path: Path to weights
      :type path: str
      :param output_model: Model to which the weights are assigned
      :type output_model: ModelEntity
      :param key: Key of the output model into which the weights are assigned
      :type key: str


   .. py:method:: _get_openvino_configuration() -> Dict[str, Any]

      Return configuration required by the exported model.


   .. py:method:: deploy(output_model: otx.api.entities.model.ModelEntity) -> None

      Exports the weights from ``output_model`` along with exportable code.

      :param output_model: Model with ``openvino.xml`` and ``.bin`` keys
      :type output_model: ModelEntity

      :raises Exception: If ``task_environment.model`` is None



