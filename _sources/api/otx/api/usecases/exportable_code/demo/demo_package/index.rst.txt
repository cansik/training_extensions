:py:mod:`otx.api.usecases.exportable_code.demo.demo_package`
============================================================

.. py:module:: otx.api.usecases.exportable_code.demo.demo_package

.. autoapi-nested-parse::

   Initialization of demo package.



Subpackages
-----------
.. toctree::
   :titlesonly:
   :maxdepth: 3

   executors/index.rst


Submodules
----------
.. toctree::
   :titlesonly:
   :maxdepth: 1

   model_container/index.rst
   utils/index.rst


Package Contents
----------------

Classes
~~~~~~~

.. autoapisummary::

   otx.api.usecases.exportable_code.demo.demo_package.AsyncExecutor
   otx.api.usecases.exportable_code.demo.demo_package.ChainExecutor
   otx.api.usecases.exportable_code.demo.demo_package.SyncExecutor
   otx.api.usecases.exportable_code.demo.demo_package.ModelContainer



Functions
~~~~~~~~~

.. autoapisummary::

   otx.api.usecases.exportable_code.demo.demo_package.create_output_converter
   otx.api.usecases.exportable_code.demo.demo_package.create_visualizer



.. py:class:: AsyncExecutor(model: otx.api.usecases.exportable_code.demo.demo_package.model_container.ModelContainer, visualizer: otx.api.usecases.exportable_code.visualizers.Visualizer)

   Async inferencer.

   :param model: model for inference
   :param visualizer: visualizer of inference results

   .. py:method:: run(input_stream: Union[int, str], loop: bool = False) -> None

      Async inference for input stream (image, video stream, camera).


   .. py:method:: render_result(results: Tuple[Any, dict]) -> numpy.ndarray

      Render for results of inference.



.. py:class:: ChainExecutor(models: List[otx.api.usecases.exportable_code.demo.demo_package.model_container.ModelContainer], visualizer: otx.api.usecases.exportable_code.visualizers.Visualizer)

   Sync executor for task-chain inference.

   :param models: list of models for inference
   :param visualizer: visualizer of inference results

   .. py:method:: single_run(input_image: numpy.ndarray) -> otx.api.entities.annotation.AnnotationSceneEntity

      Inference for single image.


   .. py:method:: crop(item: numpy.ndarray, parent_annotation: otx.api.entities.annotation.Annotation, item_annotation: otx.api.entities.annotation.Annotation) -> Tuple[numpy.ndarray, otx.api.entities.annotation.Annotation]
      :staticmethod:

      Crop operation between chain stages.


   .. py:method:: run(input_stream: Union[int, str], loop: bool = False) -> None

      Run demo using input stream (image, video stream, camera).



.. py:class:: SyncExecutor(model: otx.api.usecases.exportable_code.demo.demo_package.model_container.ModelContainer, visualizer: otx.api.usecases.exportable_code.visualizers.Visualizer)

   Synchronous executor for model inference.

   :param model: model for inference
   :type model: ModelContainer
   :param visualizer: visualizer of inference results. Defaults to None.
   :type visualizer: Visualizer

   .. py:method:: run(input_stream: Union[int, str], loop: bool = False) -> None

      Run demo using input stream (image, video stream, camera).



.. py:class:: ModelContainer(model_dir: pathlib.Path)

   Class for storing the model wrapper based on Model API and needed parameters of model.

   :param model_dir: path to model directory
   :type model_dir: Path

   .. py:method:: task_type() -> otx.api.entities.model_template.TaskType
      :property:

      Task type property.


   .. py:method:: labels() -> otx.api.entities.label_schema.LabelSchemaEntity
      :property:

      Labels property.


   .. py:method:: _initialize_wrapper() -> None
      :staticmethod:

      Load the model class.


   .. py:method:: __call__(input_data: numpy.ndarray) -> Tuple[Any, dict]

      Returns the output of the model.

      # TODO possibly unused. Remove?

      :param input_data: Input image/video data.
      :type input_data: np.ndarray

      :returns: Model predictions.
      :rtype: Tuple[Any, dict]



.. py:function:: create_output_converter(task_type: otx.api.entities.model_template.TaskType, labels: otx.api.entities.label_schema.LabelSchemaEntity)

   Create annotation converter according to kind of task.


.. py:function:: create_visualizer(_task_type: otx.api.entities.model_template.TaskType, no_show: bool = False)

   Create visualizer according to kind of task.


